{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@author: Carson Hanel\n",
    "\n",
    "Note: These code snippets are derived from Data Science from Scratch First Principles by Joel Grus.\n",
    "      For right now, I'll be transferring the code from the book, explaining the functions, and creating\n",
    "      an API that can be utilized in further analysis. While some of these functions may be part of \n",
    "      the Python standard library or a package already created, I thought it would be useful to begin\n",
    "      creating my own data science toolbelt for the future, with self written commentary.\n",
    "      \n",
    "Necessary imports/functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "def normal_cdf(x, mu=0, sigma=1):\n",
    "  return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2\n",
    "\n",
    "def inverse_normal_cdf(p, mu=0, sigma=1, tolerance=0.00001):\n",
    "  if mu != 0 or sigma != 1:\n",
    "    return mu + sigma * inverse_normal_cdf(p, tolerance=tolerance)\n",
    "            \n",
    "  low_z, low_p = -10.0, 0\n",
    "  hi_z,  hi_p  =  10.0, 1\n",
    "  while hi_z - low_z > tolerance:\n",
    "    mid_z = (low_z + hi_z) / 2\n",
    "    mid_p = normal_cdf(mid_z)\n",
    "    if mid_p < p:\n",
    "      low_z, low_p = mid_z, mid_p\n",
    "    elif mid_p > p:\n",
    "      hi_z, hi_p = mid_z, mid_p\n",
    "    else:\n",
    "      break\n",
    "                        \n",
    "  return mid_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal approximation to binomial:\n",
    "    Coin flipping trial.\n",
    "    p = 0.5\n",
    "    Each coin flip is a Bernoulli trial;\n",
    "    X is a Binomial(n, p) random variable\n",
    "   \n",
    "   You can approximate it utilizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_approximation_to_binomial(n, p):\n",
    "  mu = p * n\n",
    "  sigma = math.sqrt(p * (1 - p) * n)\n",
    "  return mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "    Whenever a random variable follows a normal distribution, we can use\n",
    "    normal_cdf to figure out the probability that its realized value lies\n",
    "    either within or outside a certain interval.\n",
    "\n",
    "Noteworthy: The normal CDF is equivalent to the probability that a variable is below a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_probability_below = normal_cdf\n",
    "  \n",
    "#It's above the threshold if it's not below the threshold\n",
    "def normal_probability_above(lo, mu=0, sigma=1):\n",
    "  return 1 - normal_cdf(lo, mu, sigma)\n",
    "  \n",
    "#It's between the threshold if it's less than hi, but not less than lo\n",
    "def normal_probability_between(lo, hi, mu=0, sigma=1):\n",
    "  return normal_cdf(hi, mu, sigma) - normal_cdf(lo, mu, sigma)\n",
    "\n",
    "#It's outside if it's not between\n",
    "def normal_probability_outside(lo, hi, mu=0, sigma=1):\n",
    "  return 1 - normal_probability_between(lo, hi, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore:\n",
    "    We can also do the reverse, finding the intervals at which likelihood cutoffs exist.\n",
    "    For example, \"if we want to find an interval centered at the mean and containing 60%\n",
    "    probability, then we find the cutoffs of the upper and lower 20%\"\n",
    "    \n",
    "    These are the methods we can utilize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_upper_bound(probability, mu=0, sigma=1):\n",
    "# returns the z for which P(Z <= z) = probability\n",
    "  return inverse_normal_cdf(probability, mu, sigma)\n",
    "\n",
    "def normal_lower_bound(probability, mu=0, sigma=1):\n",
    "# retuns the z for which P(Z >= z) = probability \n",
    "  return inverse_normal_cdf(1 - probability, mu, sigma)\n",
    "\n",
    "def normal_two_sided_bounds(probability, mu=0, sigma=1):\n",
    "# returns the symmetric (about the mean) bounds\n",
    "# that contain the specified probability  \n",
    "  tail_probability = (1 - probability) / 2\n",
    "  upper_bound      = normal_lower_bound(tail_probability, mu, sigma)\n",
    "  lower_bound      = normal_upper_bound(tail_probability, mu, sigma)\n",
    "  return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the experiment of flipping an unbiased coin 1000 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu_0, sigma_0 = normal_approximation_to_binomial(1000, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next:\n",
    "    We need to make a decision about significance.\n",
    "    How willing are we to accept an error?  \n",
    "    In this, let's choose 5% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469.01026640487555, 530.9897335951244)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_two_sided_bounds(0.95, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing:\n",
    "    Assuming the hypothesis is true, there's at most a 2.5% chance we observe a set of 1000\n",
    "    trials outside of the tested confidence interval.\n",
    "    \n",
    "    Further, we're concerned with the probability that we've made a type 2 error, or rather,\n",
    "    we've accepted the hypothesis although it is generally false in nature. To find this, we\n",
    "    calculate the \"power\" of a test, which is the probability of _not_ making a type 2 error.\n",
    "    \n",
    "    Let's check out what happens if p is actually .55 rather than .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.886548001295\n"
     ]
    }
   ],
   "source": [
    "#97.5% bounds based on assumption p is 0.5\n",
    "lo, hi = normal_two_sided_bounds(0.95, mu_0, sigma_0)\n",
    "      \n",
    "#actual mu and sigma based on p = .55\n",
    "mu_1, sigma_1 = normal_approximation_to_binomial(1000, 0.55)\n",
    "      \n",
    "#a type 2 error means we fail to reject the null hypothesis\n",
    "#which will happen when x is still in our original interval\n",
    "type_2_probability = normal_probability_between(lo, hi, mu_1, sigma_1)\n",
    "power = 1 - type_2_probability\n",
    "print(power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also:\n",
    "    Imagine that the null hypothesis was instead the the coin was not biased\n",
    "    towards heads, or rather p <= .5. \"In that case we want a one-sided test that rejects the\n",
    "    null hypothesis when X is much larger than 50 but not when X is smaller than 50. So a 5%\n",
    "    significance test involves normal_probability_below to find the cutoff below which 95% of\n",
    "    the probability lies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936379480331\n"
     ]
    }
   ],
   "source": [
    "hi = normal_upper_bound(0.95, mu_0, sigma_0)\n",
    "  \n",
    "type_2_probability = normal_probability_below(hi, mu_1, sigma_1)\n",
    "power = 1 - type_2_probability\n",
    "print(power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-sided bias test:\n",
    "    To test if the probability is actually .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_sided_p_value(x, mu=0, sigma=1):\n",
    "  if x>= mu:\n",
    "  #if x is greater than the mean, the tail is what's greater than x\n",
    "    return 2 * normal_probability_above(x, mu, sigma)\n",
    "  else:\n",
    "  #if x is less than the mean, the tail is what's less than x\n",
    "    return 2 * normal_probability_below(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to see 530 heads in 1000, we would compute:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06207721579598857"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sided_p_value(529.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tradeskill Note:\n",
    "    Utilizing 529.5 instead of 530.\n",
    "    This is called a \"continuity correction\" which reflects the fact that\n",
    "    normal_probability_between(529.5, 530.5, mu_0, sigma_0) is a better probability\n",
    "    of seeing 530 heads than normal_probability between(530, 531, mu_0, sigma_0) is.\n",
    "    \n",
    "    Nice.\n",
    "    \n",
    "One way to convince yourself that this is a sensible estimate is with a simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "extreme_value_count = 0\n",
    "for _ in range(1000000):\n",
    "  num_heads = sum(1 if random.random() < 0.5 else 0 for _ in range(1000))\n",
    "  if num_heads >= 530 or num_heads <= 470:\n",
    "    extreme_value_count += 1\n",
    "print extreme_value_count / 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is greater than our 5% significance, we don't reject the null. If we instead saw 532 heads, the p-value would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0463452878378\n"
     ]
    }
   ],
   "source": [
    "print(two_sided_p_value(531.5, mu_0, sigma_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is smaller than the 5% significance, which means we reject the null.\n",
    "Similarly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06062885772582083"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_p_value = normal_probability_above\n",
    "lower_p_value = normal_probability_below\n",
    "  \n",
    "#For a one-sided test, if we saw 525 heads, we would compute:\n",
    "upper_p_value(524.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Versus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04686839508859242"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_p_value(526.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before this point, we've only been testing hypothesis probability. When a random variable has distribution, it is wise to utilize a confidence interval to calculate the certainty of the results.\n",
    "\n",
    "The confidence in a result, if the exact probability is known, according to the central limit theorem should be approximately normal, which means it the confidence can be calculated as such:\n",
    "\n",
    "math.sqrt(p * (1 - p) / 1000)\n",
    "\n",
    "But unfortunately, the probability is not known and must be estimated as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0157916116974\n"
     ]
    }
   ],
   "source": [
    "p_hat = 525. / 1000.\n",
    "mu    = p_hat\n",
    "sigma = math.sqrt(p_hat * (1 - p_hat) / 1000)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which, apparently isn't entirely justified.\n",
    "\n",
    "If you utilize the normal approximation method, you can be 95% confident the output interval contains the true probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4940490278129096, 0.5559509721870904)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_two_sided_bounds(0.95, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which makes sense, right? the 525 out of 1000 was an example for an outcome of an unbiased coin; behold! .5 is within the confidence interval. Science!\n",
    "\n",
    "To show how the numbers vary, here's an example with 540 heads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0157607106439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5091095927295919, 0.5708904072704082)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_hat = 540. / 1000.\n",
    "mu    = p_hat\n",
    "sigma = math.sqrt(p_hat * (1 - p_hat) / 1000)\n",
    "print(sigma)\n",
    "normal_two_sided_bounds(0.95, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which, although not lying within .5 \"fair\" range, is an expected outcome. With a 95% confidence interval, 5% of given experiments will be outside of the appropriate bounds.\n",
    "\n",
    "The next topic that will be covered is P-Hacking:\n",
    "\n",
    "A procedure that erroneously rejects the null hypothesis only 5% of the time will - by definition - 5% of the time erroneously reject the null hypothesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "# Flip a fair coin 1000 times, True = heads, False = tails\n",
    "def run_experiment():\n",
    "    return [random.random() < 0.5 for _ in range(1000)]\n",
    "\n",
    "# Using the 5% significance levels\n",
    "def reject_fairness(experiment):\n",
    "    num_heads = len([flip for flip in experiment if flip])\n",
    "    return num_heads < 469 or num_heads > 531\n",
    "\n",
    "random.seed(0)\n",
    "experiments = [run_experiment() for _ in range(1000)]\n",
    "num_rejects = len([experiment \n",
    "                   for experiment in experiments \n",
    "                   if reject_fairness(experiment)])\n",
    "print num_rejects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, the author is showing you a medium of being able to force the .05 p-value interval to force correlations between variables. The author explains that this technique is a circumvention of common sense and should not be used to \"mine features\", rather you should apply common sense to your data.\n",
    "\n",
    "Personally, I believe if you can mine features and explore causation, that's what data science is all about.\n",
    "\n",
    "The author continues to provide an example of an A/B test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
