{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to my notes on Data Gathering!\n",
    "\n",
    "As an aside, please remember that this code is written alongside Joel Grus' book \"Data Science from Scratch\" and is not uniquely my own. However, the code and comments are all hand written to ensure the longevity of the studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-3ef1a9c3080d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mmatch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%f percent of lines contained the regular expression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "#egrep.py\n",
    "import sys, re\n",
    "\n",
    "# sys.argv is the list of command-line arguments\n",
    "# sys.argv[0] is the name of the program itself\n",
    "# sys.argv[1] will be the regex specified at the command-line\n",
    "regex = sys.argv[1]\n",
    "count = 0\n",
    "match = 0\n",
    "\n",
    "# for every line passed into the script\n",
    "for line in sys.stdin:\n",
    "    count += 1\n",
    "    # if it matches the regex, write it to stdout\n",
    "    if re.search(regex, line):\n",
    "        sys.stdout.write(line)\n",
    "        match += 1\n",
    "print(\"%f percent of lines contained the regular expression\", match/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to call from the commandline in Windows to count the percent of lines in a file contain a number, you'd utilize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type SomeFile.txt | python egrep.py \"[0-9]\" | python line_count.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas, a Unix system would utilize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat SomeFile.txt | python egrep.py \"[0-9]\" | python line_count.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a little function to write the most commonly occurring words in a given set of information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-7ea29853c228>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-7ea29853c228>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    try:\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "try:\n",
    "    num_words = int(sys.argv[1])\n",
    "except:\n",
    "    print \"usage: most_common_words.py num_words\"\n",
    "    sys.exit(1)\n",
    "    \n",
    "counter = Counter(word.lower()\n",
    "                  for line in sys.stdin\n",
    "                  for word in line.strip().split()\n",
    "                  if  word)\n",
    "\n",
    "for word, count in counter.most_common(num_words):\n",
    "    sys.stdout.write(str(count))\n",
    "    sys.stdout.write(\"\\t\")\n",
    "    sys.stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After which you'd call it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type the_bible.txt | python most_common_words.py 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a simple natural language processing technique to find word frequency given a document. You can do further analysis by looking at features that can be engineered from these numbers, for example, the \"Term Frequency - Inverse Document Frequency\" that puts more emphasis on rarer words.\n",
    "\n",
    "To continue, the textbook covers on some simple CSV reading and processing in Python. I don't feel this is necessary to write here, so I'm just going to skip straight to the web scraping portion.\n",
    "\n",
    "HTML and the Parsing Thereof:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is just example HTML, not meant for running.\n",
    "<html>\n",
    "    <head>\n",
    "        <title>A web page</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p id=\"author\">Joel Grus</p>\n",
    "        <p id=\"subject\">Data Science</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import the necessary tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html><head>\n",
      "    <title>Example Domain</title>\n",
      "\n",
      "    <meta charset=\"utf-8\"/>\n",
      "    <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-type\"/>\n",
      "    <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "    <style type=\"text/css\">\n",
      "    body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 50px;\n",
      "        background-color: #fff;\n",
      "        border-radius: 1em;\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        body {\n",
      "            background-color: #fff;\n",
      "        }\n",
      "        div {\n",
      "            width: auto;\n",
      "            margin: 0 auto;\n",
      "            border-radius: 0;\n",
      "            padding: 1em;\n",
      "        }\n",
      "    }\n",
      "    </style>    \n",
      "</head>\n",
      "\n",
      "<body>\n",
      "<div>\n",
      "    <h1>Example Domain</h1>\n",
      "    <p>This domain is established to be used for illustrative examples in documents. You may use this\n",
      "    domain in examples without prior coordination or asking for permission.</p>\n",
      "    <p><a href=\"http://www.iana.org/domains/example\">More information...</a></p>\n",
      "</div>\n",
      "\n",
      "\n",
      "</body></html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "html = requests.get(\"http://www.example.com\").text\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>This domain is established to be used for illustrative examples in documents. You may use this\n",
      "    domain in examples without prior coordination or asking for permission.</p>\n"
     ]
    }
   ],
   "source": [
    "# Extracting the first paragraph:\n",
    "first_paragraph = soup.find('p')\n",
    "print(first_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just the texts: This domain is established to be used for illustrative examples in documents. You may use this\n",
      "    domain in examples without prior coordination or asking for permission.\n",
      "\n",
      "Just the words: [u'This', u'domain', u'is', u'established', u'to', u'be', u'used', u'for', u'illustrative', u'examples', u'in', u'documents.', u'You', u'may', u'use', u'this', u'domain', u'in', u'examples', u'without', u'prior', u'coordination', u'or', u'asking', u'for', u'permission.']\n"
     ]
    }
   ],
   "source": [
    "# Extracting just the text contents:\n",
    "first_paragraph_text = soup.p.text\n",
    "first_paragraph_word = soup.p.text.split()\n",
    "print(\"Just the texts: \" + str(first_paragraph_text) + \"\\n\")\n",
    "print(\"Just the words: \" + str(first_paragraph_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First paragraph id: None\n"
     ]
    }
   ],
   "source": [
    "# Extracting the textual contents in a dictionary fashion\n",
    "first_paragraph_id   = soup.p.get('id') # returns None if no 'id'\n",
    "#first_paragraph_id2  = soup.p['id']     # raises a key error if not extant\n",
    "print(\"First paragraph id: \" + str(first_paragraph_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All paragraphs: [<p>This domain is established to be used for illustrative examples in documents. You may use this\\n    domain in examples without prior coordination or asking for permission.</p>, <p><a href=\"http://www.iana.org/domains/example\">More information...</a></p>]\n",
      "IDs: None\n"
     ]
    }
   ],
   "source": [
    "# Extracting multiple tags:\n",
    "all_paragraphs      = soup.find_all('p')\n",
    "paragraphs_with_ids = soup.p.get('id')\n",
    "print(\"All paragraphs: \" + str(all_paragraphs))\n",
    "print(\"IDs: \" + str(paragraphs_with_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting tags with a specific class:\n",
    "important_paragraphs  = soup('p', {'class' : 'important'})\n",
    "important_paragraphs2 = soup('p', 'important')\n",
    "important_paragraphs3 = [p for p in soup('p')\n",
    "                         if 'important' in p.get('class', [])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A treatise in Analysis:\n",
    "\n",
    "This is an example of data scraping for analysis from the O'Reilly book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n",
      "<html><head>\n",
      "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "<meta content=\"text/javascript\" http-equiv=\"Content-Script-Type\"/>\n",
      "<script type=\"text/javascript\">\n",
      "function getCookie(c_name) { // Local function for getting a cookie value\n",
      "    if (document.cookie.length > 0) {\n",
      "        c_start = document.cookie.indexOf(c_name + \"=\");\n",
      "        if (c_start!=-1) {\n",
      "        c_start=c_start + c_name.length + 1;\n",
      "        c_end=document.cookie.indexOf(\";\", c_start);\n",
      "\n",
      "        if (c_end==-1) \n",
      "            c_end = document.cookie.length;\n",
      "\n",
      "        return unescape(document.cookie.substring(c_start,c_end));\n",
      "        }\n",
      "    }\n",
      "    return \"\";\n",
      "}\n",
      "function setCookie(c_name, value, expiredays) { // Local function for setting a value of a cookie\n",
      "    var exdate = new Date();\n",
      "    exdate.setDate(exdate.getDate()+expiredays);\n",
      "    document.cookie = c_name + \"=\" + escape(value) + ((expiredays==null) ? \"\" : \";expires=\" + exdate.toGMTString()) + \";path=/\";\n",
      "}\n",
      "function getHostUri() {\n",
      "    var loc = document.location;\n",
      "    return loc.toString();\n",
      "}\n",
      "setCookie('YPF8827340282Jdskjhfiw_928937459182JAX666', '165.91.13.112', 10);\n",
      "try {  \n",
      "    location.reload(true);  \n",
      "} catch (err1) {  \n",
      "    try {  \n",
      "        location.reload();  \n",
      "    } catch (err2) {  \n",
      "    \tlocation.href = getHostUri();  \n",
      "    }  \n",
      "}\n",
      "</script>\n",
      "</head>\n",
      "<body>\n",
      "<noscript>This site requires JavaScript and Cookies to be enabled. Please change your browser settings or upgrade your browser.</noscript>\n",
      "\n",
      "\n",
      "</body></html>\n"
     ]
    }
   ],
   "source": [
    "url  = \"http://shop.oreilley.com/category/browse-subjects/\" + \\\n",
    "       \"data.do?sortby=publicationDate&page=1\"\n",
    "soup = BeautifulSoup(requests.get(url).text, 'html5lib')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we've done at this point "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
